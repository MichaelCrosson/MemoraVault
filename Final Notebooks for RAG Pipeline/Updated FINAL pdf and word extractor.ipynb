{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7730ae36-17d1-46a7-b781-758a7905cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the folder containing PDF/DOCX files:  /Users/advaith/Desktop/MSBA Related coursework/Spring term/Deep Learning/Final Project/pdf files\n",
      "Enter the path to save the extracted text JSON file:  /Users/advaith/Desktop/MSBA Related coursework/Spring term/Deep Learning/Final Project/Data to be considered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: AML Quiz 1 Study Guide.pdf\n",
      "Extracted 1 content items from all files.\n",
      "Extracted text saved to: /Users/advaith/Desktop/MSBA Related coursework/Spring term/Deep Learning/Final Project/Data to be considered/extracted_text.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2  \n",
    "import docx    \n",
    "import json\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    # Replace all whitespace (including newlines) with a single space\n",
    "                    cleaned_text = \" \".join(page_text.split())\n",
    "                    text += cleaned_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def extract_text_from_word(doc_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(doc_path)\n",
    "        text = \"\\n\".join(para.text for para in doc.paragraphs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {doc_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def process_documents(folder_path):\n",
    "    \"\"\"\n",
    "    Process all PDF and DOCX files in the folder and convert them into a list of\n",
    "    content items (dictionaries) in the format expected by the RAG pipeline.\n",
    "    \"\"\"\n",
    "    extracted_items = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            print(f\"Processing PDF: {filename}\")\n",
    "            pdf_text = extract_text_from_pdf(file_path)\n",
    "            if pdf_text.strip():\n",
    "                content_item = {\n",
    "                    \"video_id\": filename,       # Use the filename as an ID\n",
    "                    \"frame\": \"full_text\",       # Use a placeholder since it's a full document\n",
    "                    \"timestamp\": \"0:00\",        # No timestamp for a full document\n",
    "                    \"timestamp_seconds\": 0,     # Default value\n",
    "                    \"content\": pdf_text\n",
    "                }\n",
    "                extracted_items.append(content_item)\n",
    "        \n",
    "        elif filename.lower().endswith('.docx'):\n",
    "            print(f\"Processing Word Document: {filename}\")\n",
    "            word_text = extract_text_from_word(file_path)\n",
    "            if word_text.strip():\n",
    "                content_item = {\n",
    "                    \"video_id\": filename,       # Use the filename as an ID\n",
    "                    \"frame\": \"full_text\",\n",
    "                    \"timestamp\": \"0:00\",\n",
    "                    \"timestamp_seconds\": 0,\n",
    "                    \"content\": word_text\n",
    "                }\n",
    "                extracted_items.append(content_item)\n",
    "    \n",
    "    return extracted_items\n",
    "\n",
    "def main():\n",
    "    # Prompt for input and output folders\n",
    "    input_folder = input(\"Enter the path to the folder containing PDF/DOCX files: \").strip()\n",
    "    output_folder = input(\"Enter the path to save the extracted text JSON file: \").strip()\n",
    "    \n",
    "    # Validate paths\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: The input folder '{input_folder}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created output folder: {output_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating output folder: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Process documents and get a list of content items in the desired format\n",
    "    content_items = process_documents(input_folder)\n",
    "    print(f\"Extracted {len(content_items)} content items from all files.\")\n",
    "    \n",
    "    # Save the output JSON in the desired format\n",
    "    output_file = os.path.join(output_folder, \"extracted_text.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(content_items, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Extracted text saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102827c-498a-4be6-bf5a-6705edde5c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
